import joern
import networkx as nx
import pandas as pd
def feature_extraction(filepath):
    """Extract relevant components of IVDetect Code Representation."""
    try:
        nodes, edges = joern.get_node_edges(filepath)
    except:
        return None

    # 1. Generate tokenised subtoken sequences
    subseq = (
        nodes.sort_values(by="code", key=lambda x: x.str.len(), ascending=False)
        .groupby("lineNumber")
        .head(1)
    )
    subseq = subseq[["lineNumber", "code", "local_type"]].copy()
    subseq.code = subseq.local_type + " " + subseq.code
    subseq = subseq.drop(columns="local_type")
    subseq = subseq[~subseq.eq("").any(1)]
    subseq = subseq[subseq.code != " "]
    subseq.lineNumber = subseq.lineNumber.astype(int)
    subseq = subseq.sort_values("lineNumber")
    # subseq.code = subseq.code.apply(svdt.tokenise)
    subseq = subseq.set_index("lineNumber").to_dict()["code"]
    print(subseq)


    # 2. Line to AST
    ast_edges = joern.rdg(edges, "ast")
    ast_nodes = joern.drop_lone_nodes(nodes, ast_edges)
    ast_nodes = ast_nodes[ast_nodes.lineNumber != ""]
    ast_nodes.lineNumber = ast_nodes.lineNumber.astype(int)
    ast_nodes["lineidx"] = ast_nodes.groupby("lineNumber").cumcount().values
    ast_edges = ast_edges[ast_edges.line_out == ast_edges.line_in]
    ast_dict = pd.Series(ast_nodes.lineidx.values, index=ast_nodes.id).to_dict()
    ast_edges.innode = ast_edges.innode.map(ast_dict)
    ast_edges.outnode = ast_edges.outnode.map(ast_dict)
    ast_edges = ast_edges.groupby("line_in").agg({"innode": list, "outnode": list})
    # ast_nodes.code = ast_nodes.code.fillna("").apply(svdt.tokenise)
    ast_nodes.code = ast_nodes.code.fillna("")
    nodes_per_line = (
        ast_nodes.groupby("lineNumber").agg({"lineidx": list}).to_dict()["lineidx"]
    )
    ast_nodes = ast_nodes.groupby("lineNumber").agg({"code": list})
    ast = ast_edges.join(ast_nodes, how="inner")
    ast["ast"] = ast.apply(lambda x: [x.outnode, x.innode, x.code], axis=1)
    ast = ast.to_dict()["ast"]

    # If it is a lone node (nodeid doesn't appear in edges) or it is a node with no
    # incoming connections (parent node), then add an edge from that node to the node
    # with id = 0 (unless it is zero itself).
    # DEBUG:
    # import sastvd.helpers.graphs as svdgr
    # svdgr.simple_nx_plot(ast[20][0], ast[20][1], ast[20][2])
    for k, v in ast.items():
        allnodes = nodes_per_line[k]
        outnodes = v[0]
        innodes = v[1]
        lonenodes = [i for i in allnodes if i not in outnodes + innodes]
        parentnodes = [i for i in outnodes if i not in innodes]
        for n in set(lonenodes + parentnodes) - set([0]):
            outnodes.append(0)
            innodes.append(n)
        ast[k] = [outnodes, innodes, v[2]]

    # 3. Variable names and types
    reftype_edges = joern.rdg(edges, "reftype")
    reftype_nodes = joern.drop_lone_nodes(nodes, reftype_edges)
    reftype_nx = nx.Graph()
    reftype_nx.add_edges_from(reftype_edges[["innode", "outnode"]].to_numpy())
    reftype_cc = list(nx.connected_components(reftype_nx))
    varnametypes = list()
    for cc in reftype_cc:
        cc_nodes = reftype_nodes[reftype_nodes.id.isin(cc)]
        var_type = cc_nodes[cc_nodes["_label"] == "TYPE"].name.item()
        for idrow in cc_nodes[cc_nodes["_label"] == "IDENTIFIER"].itertuples():
            varnametypes += [[idrow.lineNumber, var_type, idrow.name]]
    nametypes = pd.DataFrame(varnametypes, columns=["lineNumber", "type", "name"])
    nametypes = nametypes.drop_duplicates().sort_values("lineNumber")
    # nametypes.type = nametypes.type.apply(svdt.tokenise)
    # nametypes.name = nametypes.name.apply(svdt.tokenise)
    nametypes["nametype"] = nametypes.type + " " + nametypes.name
    nametypes = nametypes.groupby("lineNumber").agg({"nametype": lambda x: " ".join(x)})
    nametypes = nametypes.to_dict()["nametype"]

    # 4/5. Data dependency / Control dependency context
    # Group nodes into statements
    nodesline = nodes[nodes.lineNumber != ""].copy()
    nodesline.lineNumber = nodesline.lineNumber.astype(int)
    nodesline = (
        nodesline.sort_values(by="code", key=lambda x: x.str.len(), ascending=False)
        .groupby("lineNumber")
        .head(1)
    )
    edgesline = edges.copy()
    edgesline.innode = edgesline.line_in
    edgesline.outnode = edgesline.line_out
    nodesline.id = nodesline.lineNumber
    edgesline = joern.rdg(edgesline, "pdg")
    nodesline = joern.drop_lone_nodes(nodesline, edgesline)
    # Drop duplicate edges
    edgesline = edgesline.drop_duplicates(subset=["innode", "outnode", "etype"])
    # REACHING DEF to DDG
    edgesline["etype"] = edgesline.apply(
        lambda x: "DDG" if x.etype == "REACHING_DEF" else x.etype, axis=1
    )
    edgesline = edgesline[edgesline.innode.apply(lambda x: isinstance(x, float))]
    edgesline = edgesline[edgesline.outnode.apply(lambda x: isinstance(x, float))]
    edgesline_reverse = edgesline[["innode", "outnode", "etype"]].copy()
    edgesline_reverse.columns = ["outnode", "innode", "etype"]
    uedge = pd.concat([edgesline, edgesline_reverse])
    uedge = uedge[uedge.innode != uedge.outnode]
    uedge = uedge.groupby(["innode", "etype"]).agg({"outnode": set})
    uedge = uedge.reset_index()
    if len(uedge) > 0:
        uedge = uedge.pivot("innode", "etype", "outnode")
        if "DDG" not in uedge.columns:
            uedge["DDG"] = None
        if "CDG" not in uedge.columns:
            uedge["CDG"] = None
        uedge = uedge.reset_index()[["innode", "CDG", "DDG"]]
        uedge.columns = ["lineNumber", "control", "data"]
        uedge.control = uedge.control.apply(
            lambda x: list(x) if isinstance(x, set) else []
        )
        uedge.data = uedge.data.apply(lambda x: list(x) if isinstance(x, set) else [])
        data = uedge.set_index("lineNumber").to_dict()["data"]
        control = uedge.set_index("lineNumber").to_dict()["control"]
    else:
        data = {}
        control = {}

    # Generate PDG
    pdg_nodes = nodesline.copy()
    pdg_nodes = pdg_nodes[["id"]].sort_values("id")
    pdg_nodes["subseq"] = pdg_nodes.id.map(subseq).fillna("")
    pdg_nodes["ast"] = pdg_nodes.id.map(ast).fillna("")
    pdg_nodes["nametypes"] = pdg_nodes.id.map(nametypes).fillna("")
    pdg_nodes["data"] = pdg_nodes.id.map(data)
    pdg_nodes["control"] = pdg_nodes.id.map(control)
    pdg_edges = edgesline.copy()
    pdg_nodes = pdg_nodes.reset_index(drop=True).reset_index()
    pdg_dict = pd.Series(pdg_nodes.index.values, index=pdg_nodes.id).to_dict()
    pdg_edges.innode = pdg_edges.innode.map(pdg_dict)
    pdg_edges.outnode = pdg_edges.outnode.map(pdg_dict)
    pdg_edges = pdg_edges.dropna()
    pdg_edges = (pdg_edges.outnode.tolist(), pdg_edges.innode.tolist())

    # # Cache
    # with open(cachefp, "wb") as f:
    #     pkl.dump([pdg_nodes, pdg_edges], f)
    return pdg_nodes, pdg_edges

#C:/Users/ASUS/PycharmProjects/pythonProject4/Code3/New/test/test.c
filepath = 'C:/Users/ASUS/PycharmProjects/pythonProject4/Code3/New/test/http_32/http_32.c'
res = joern.full_run_joern(filepath)


print(res['nodes'])
print(res['edges'])

# res['nodes'].to_csv(filepath + '.nodes.csv')
# res['edges'].to_csv(filepath + '.edges.csv')

nodes, edges = joern.get_node_edges(filepath)
joern.plot_graph_node_edge_df(nodes, joern.rdg(edges,'pdg'))


nodes.to_csv(filepath + '.nodes.csv')
edges.to_csv(filepath + '.edges.csv')

# print(res['nodes'])
# print(res['edges'])

subseq = (
        nodes.sort_values(by="code", key=lambda x: x.str.len(), ascending=False)
        .groupby("lineNumber")
        .head(1)
    )
subseq = subseq[["lineNumber", "code", "local_type"]].copy()
subseq.code = subseq.local_type + " " + subseq.code
subseq = subseq.drop(columns="local_type")
# Add these print statements before the line that raises the error
print("Shape of subseq DataFrame:", subseq.shape)
print("Index of subseq DataFrame:", subseq.index)
print("Shape of boolean Series:", (~subseq.eq("").any(axis=1)).shape)
print("Index of boolean Series:", (~subseq.eq("").any(axis=1)).index)
print("Before filtering:")
print(subseq)
subseq = subseq[~subseq.eq("").any(axis=1)]
print("After filtering:")
print(subseq)
subseq = subseq[subseq.code != " "]
subseq.lineNumber = subseq.lineNumber.astype(int)
subseq = subseq.sort_values("lineNumber")
# subseq.code = subseq.code.apply(svdt.tokenise)
subseq = subseq.set_index("lineNumber").to_dict()["code"]

# print(subseq)

ast_edges = joern.rdg(edges, "ast")
ast_nodes = joern.drop_lone_nodes(nodes, ast_edges)
ast_nodes = ast_nodes[ast_nodes.lineNumber != ""]
ast_nodes.lineNumber = ast_nodes.lineNumber.astype(int)
ast_nodes["lineidx"] = ast_nodes.groupby("lineNumber").cumcount().values
ast_edges = ast_edges[ast_edges.line_out == ast_edges.line_in]
ast_dict = pd.Series(ast_nodes.lineidx.values, index=ast_nodes.id).to_dict()
ast_edges.innode = ast_edges.innode.map(ast_dict)
ast_edges.outnode = ast_edges.outnode.map(ast_dict)
ast_edges = ast_edges.groupby("line_in").agg({"innode": list, "outnode": list})
# ast_nodes.code = ast_nodes.code.fillna("").apply(svdt.tokenise)
ast_nodes.code = ast_nodes.code.fillna("")
nodes_per_line = (
    ast_nodes.groupby("lineNumber").agg({"lineidx": list}).to_dict()["lineidx"]
)
ast_nodes = ast_nodes.groupby("lineNumber").agg({"code": list})
ast = ast_edges.join(ast_nodes, how="inner")
ast["ast"] = ast.apply(lambda x: [x.outnode, x.innode, x.code], axis=1)
ast = ast.to_dict()["ast"]

for k, v in ast.items():
        allnodes = nodes_per_line[k]
        outnodes = v[0]
        innodes = v[1]
        lonenodes = [i for i in allnodes if i not in outnodes + innodes]
        parentnodes = [i for i in outnodes if i not in innodes]
        for n in set(lonenodes + parentnodes) - set([0]):
            outnodes.append(0)
            innodes.append(n)
        ast[k] = [outnodes, innodes, v[2]]


# print('ast')
# print(ast)


reftype_edges = joern.rdg(edges, "reftype")
reftype_nodes = joern.drop_lone_nodes(nodes, reftype_edges)
reftype_nx = nx.Graph()
reftype_nx.add_edges_from(reftype_edges[["innode", "outnode"]].to_numpy())
reftype_cc = list(nx.connected_components(reftype_nx))
varnametypes = list()
for cc in reftype_cc:
    cc_nodes = reftype_nodes[reftype_nodes.id.isin(cc)]
    var_type = cc_nodes[cc_nodes["_label"] == "TYPE"].name.item()
    for idrow in cc_nodes[cc_nodes["_label"] == "IDENTIFIER"].itertuples():
        varnametypes += [[idrow.lineNumber, var_type, idrow.name]]
nametypes = pd.DataFrame(varnametypes, columns=["lineNumber", "type", "name"])
nametypes = nametypes.drop_duplicates().sort_values("lineNumber")
# nametypes.type = nametypes.type.apply(svdt.tokenise)
# nametypes.name = nametypes.name.apply(svdt.tokenise)
nametypes["nametype"] = nametypes.type + " " + nametypes.name
nametypes = nametypes.groupby("lineNumber").agg({"nametype": lambda x: " ".join(x)})
nametypes = nametypes.to_dict()["nametype"]

# print('nametypes')
# print(nametypes)

nodesline = nodes[nodes.lineNumber != ""].copy()
nodesline.lineNumber = nodesline.lineNumber.astype(int)
nodesline = (
    nodesline.sort_values(by="code", key=lambda x: x.str.len(), ascending=False)
    .groupby("lineNumber")
    .head(1)
)
edgesline = edges.copy()
edgesline.innode = edgesline.line_in
edgesline.outnode = edgesline.line_out
nodesline.id = nodesline.lineNumber
edgesline = joern.rdg(edgesline, "pdg")
nodesline = joern.drop_lone_nodes(nodesline, edgesline)
# Drop duplicate edges
edgesline = edgesline.drop_duplicates(subset=["innode", "outnode", "etype"])
# REACHING DEF to DDG
edgesline["etype"] = edgesline.apply(
    lambda x: "DDG" if x.etype == "REACHING_DEF" else x.etype, axis=1
)
edgesline = edgesline[edgesline.innode.apply(lambda x: isinstance(x, float))]
edgesline = edgesline[edgesline.outnode.apply(lambda x: isinstance(x, float))]
edgesline_reverse = edgesline[["innode", "outnode", "etype"]].copy()
edgesline_reverse.columns = ["outnode", "innode", "etype"]
uedge = pd.concat([edgesline, edgesline_reverse])
uedge = uedge[uedge.innode != uedge.outnode]
uedge = uedge.groupby(["innode", "etype"]).agg({"outnode": set})
uedge = uedge.reset_index()
if len(uedge) > 0:
    uedge = uedge.pivot(index="innode", columns="etype", values="outnode")
    if "DDG" not in uedge.columns:
        uedge["DDG"] = None
    if "CDG" not in uedge.columns:
        uedge["CDG"] = None
    uedge = uedge.reset_index()[["innode", "CDG", "DDG"]]
    uedge.columns = ["lineNumber", "control", "data"]
    uedge.control = uedge.control.apply(
        lambda x: list(x) if isinstance(x, set) else []
    )
    uedge.data = uedge.data.apply(lambda x: list(x) if isinstance(x, set) else [])
    data = uedge.set_index("lineNumber").to_dict()["data"]
    control = uedge.set_index("lineNumber").to_dict()["control"]
else:
    data = {}
    control = {}

# print('nodesline')
# print('edgesline')

edgesline = edgesline[edgesline.innode != edgesline.outnode]


nodesline.to_csv (filepath + '.nodesline.csv')
edgesline.to_csv (filepath + '.edgesline.csv')

pdg_nodes = nodesline.copy()
pdg_nodes = pdg_nodes[["id"]].sort_values("id")
pdg_nodes["subseq"] = pdg_nodes.id.map(subseq).fillna("")
pdg_nodes["ast"] = pdg_nodes.id.map(ast).fillna("")
pdg_nodes["nametypes"] = pdg_nodes.id.map(nametypes).fillna("")
pdg_nodes["data"] = pdg_nodes.id.map(data)
pdg_nodes["control"] = pdg_nodes.id.map(control)
pdg_edges = edgesline.copy()
pdg_nodes = pdg_nodes.reset_index(drop=True).reset_index()
pdg_dict = pd.Series(pdg_nodes.index.values, index=pdg_nodes.id).to_dict()
pdg_edges.innode = pdg_edges.innode.map(pdg_dict)
pdg_edges.outnode = pdg_edges.outnode.map(pdg_dict)
pdg_edges = pdg_edges.dropna()
# pdg_edges = (pdg_edges.outnode.tolist(), pdg_edges.innode.tolist())

# print('pdg_nodes_edges')

pdg_edges = pdg_edges[pdg_edges.innode != pdg_edges.outnode]

pdg_nodes.to_csv(filepath + '.pdg_nodes.csv')
pdg_edges.to_csv(filepath + '.pdg_edges.csv')


# print(pdg_nodes)
# print(pdg_edges)

#joern.plot_graph_node_edge_df(nodesline, edgesline)
edgesline = edgesline.sort_values('outnode')
# print(edgesline)

nodesline['newcode'] = nodesline.code

for i, e in edgesline.iterrows():
    # print(e['innode'], e['outnode'], e['dataflow'])

    for j, n in nodesline.iterrows():
        if e['innode'] == n['id']:
            n['newcode'] += ',' + e['dataflow']
            nodesline.loc[j, 'newcode'] = n['newcode']
         
# print(nodesline['newcode'])

nodesline.to_csv(filepath + '.updated_nodes.csv')